<!doctype html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="YOLO：CoreML与MPSNNGraph译者：thinkdeeper 原文：http://machinethink.net/blog/yolo-coreml-versus-mps-graph/  导读： 今年6月6日，苹果WWDC不仅放出了惊艳的硬件，还首次公布了机器学习方面的动作（似乎，科技公司如不公布自己的机器学习产品，就不能称为科技公司了（：）。machine learning 和 co">
<meta property="og:type" content="article">
<meta property="og:title" content="test">
<meta property="og:url" content="http://yoursite.com/2017/06/30/test/index.html">
<meta property="og:site_name" content="灵感栖息地">
<meta property="og:description" content="YOLO：CoreML与MPSNNGraph译者：thinkdeeper 原文：http://machinethink.net/blog/yolo-coreml-versus-mps-graph/  导读： 今年6月6日，苹果WWDC不仅放出了惊艳的硬件，还首次公布了机器学习方面的动作（似乎，科技公司如不公布自己的机器学习产品，就不能称为科技公司了（：）。machine learning 和 co">
<meta property="og:image" content="http://machinethink.net/images/yolo-coreml-mps-graph/Dog.png">
<meta property="og:image" content="http://machinethink.net/images/yolo-coreml-mps-graph/Eagle.png">
<meta property="og:image" content="http://machinethink.net/images/yolo-coreml-mps-graph/Person.png">
<meta property="og:image" content="http://yoursite.com/Users/thinkdeeper/FarBox/thinker.farbox.com/_image/about/21-54-35.jpg">
<meta property="og:updated_time" content="2017-06-30T15:40:22.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="test">
<meta name="twitter:description" content="YOLO：CoreML与MPSNNGraph译者：thinkdeeper 原文：http://machinethink.net/blog/yolo-coreml-versus-mps-graph/  导读： 今年6月6日，苹果WWDC不仅放出了惊艳的硬件，还首次公布了机器学习方面的动作（似乎，科技公司如不公布自己的机器学习产品，就不能称为科技公司了（：）。machine learning 和 co">
<meta name="twitter:image" content="http://machinethink.net/images/yolo-coreml-mps-graph/Dog.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/06/30/test/"/>





  <title>test | 灵感栖息地</title>
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">灵感栖息地</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/06/30/test/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ghg">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="灵感栖息地">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">test</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-30T23:39:34+08:00">
                2017-06-30
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="YOLO：CoreML与MPSNNGraph"><a href="#YOLO：CoreML与MPSNNGraph" class="headerlink" title="YOLO：CoreML与MPSNNGraph"></a>YOLO：CoreML与MPSNNGraph</h1><p>译者：thinkdeeper</p>
<p>原文：<a href="http://machinethink.net/blog/yolo-coreml-versus-mps-graph/" target="_blank" rel="external">http://machinethink.net/blog/yolo-coreml-versus-mps-graph/</a></p>
<blockquote>
<p>导读：</p>
<p>今年6月6日，苹果WWDC不仅放出了惊艳的硬件，还首次公布了机器学习方面的动作（似乎，科技公司如不公布自己的机器学习产品，就不能称为科技公司了（：）。machine learning 和 computer vision 在iOS系统早已支持，但这次苹果提供了更合理，容易上手的api，让那些对基础理论知识一窍不通的门外汉也能玩转高大上的前沿科技。这篇文章介绍了通过最新API把YOLO模型集成到APP中的两种方法。</p>
</blockquote>
<p>几周前，我写了篇关于YOLO（一个用于目标检测的神经网络模型）的教程。并且我使用Metal Performance Shader和我的 <a href="https://github.com/hollance/Forge" target="_blank" rel="external">Forge神经网络库</a>，实现了该版本的YOLO（实际上是Tiny YOLO）。</p>
<blockquote>
<p><a href="http://machinethink.net/blog/object-detection-with-yolo/" target="_blank" rel="external">http://machinethink.net/blog/object-detection-with-yolo/</a></p>
<p>Forge神经网络库- <a href="https://github.com/hollance/Forge" target="_blank" rel="external">https://github.com/hollance/Forge</a></p>
</blockquote>
<p>此后，苹果公司宣布了可以在设备上应用机器学习的<a href="http://machinethink.net/blog/ios-11-machine-learning-for-everyone/" target="_blank" rel="external">两种新技术</a>：<strong>Core ML</strong>和<strong>MPS graph API</strong>（Core ML 构建于MPS之上，MPS更底层）。在这篇博文中，我们会使用这些新的API来实现Tiny YOLO。</p>
<blockquote>
<p>-<a href="http://machinethink.net/blog/ios-11-machine-learning-for-everyone" target="_blank" rel="external">http://machinethink.net/blog/ios-11-machine-learning-for-everyone</a></p>
</blockquote>
<p><a href="http://machinethink.net/images/yolo-coreml-mps-graph/Dog@2x.png" target="_blank" rel="external"><img src="http://machinethink.net/images/yolo-coreml-mps-graph/Dog.png" alt="小YOLO在行动"></a></p>
<p>快速回顾：YOLO是由9个卷积层和6个最大池化层组成的神经网络，但其最后一层不会像分类器那样输出概率分布。相反，最后一层产生13×13×125张量。</p>
<p>该输出张量描述了13×13个单元格。每个单元格预测5个边界框（每个边界框由25个数字描述）。然后，我们使用非最大抑制来找到最佳边界框。</p>
<p>您可以<a href="https://github.com/hollance/YOLO-CoreML-MPSNNGraph" target="_blank" rel="external">在GitHub上找到</a>此博文的源代码。</p>
<blockquote>
<p>GitHub -<a href="https://github.com/hollance/YOLO-CoreML-MPSNNGraph" target="_blank" rel="external">https://github.com/hollance/YOLO-CoreML-MPSNNGraph</a></p>
</blockquote>
<p><strong>注意：要运行演示应用程序，需要使用Xcode 9和具有iOS 11的设备。两者都处于测试阶段。此博客文章是Beta 2的最新版本 - 如果您使用的是不同的测试版，可能会得到不同的结果</strong>。</p>
<h2 id="YOLO与Core-ML"><a href="#YOLO与Core-ML" class="headerlink" title="YOLO与Core ML"></a>YOLO与Core ML</h2><p>我们从Core ML开始，因为大多数开发人员希望用此框架将机器学习放入他们的应用程序中。接下来，打开Xcode中的<strong>TinyYOLO-CoreML</strong>项目。</p>
<p>第一步是创建描述YOLO神经网络的<strong>.mlmodel</strong>文件。</p>
<p>好消息：<a href="http://pjreddie.com/darknet/yolo/" target="_blank" rel="external">YOLO</a>的<a href="http://pjreddie.com/darknet/yolo/" target="_blank" rel="external">作者</a>已经提供了一个预先训练的网络，所以我们不必自己做任何训练。</p>
<blockquote>
<p>yolo author-<a href="http://pjreddie.com/darknet/yolo/" target="_blank" rel="external">http://pjreddie.com/darknet/yolo/</a></p>
</blockquote>
<p>坏消息：它是Darknet格式。该<a href="https://pypi.python.org/pypi/coremltools" target="_blank" rel="external">Core ML conversion tools</a>不支持Darknet，所以我们先把Darknet转换为Keras格式。然后我们可以从Keras转换为Core ML。</p>
<blockquote>
<p>Core ML conversion tools-<a href="https://pypi.python.org/pypi/coremltools" target="_blank" rel="external">https://pypi.python.org/pypi/coremltools</a></p>
</blockquote>
<h3 id="步骤1：Darknet-to-Keras-1-2-2"><a href="#步骤1：Darknet-to-Keras-1-2-2" class="headerlink" title="步骤1：Darknet to Keras 1.2.2"></a>步骤1：Darknet to Keras 1.2.2</h3><p>在我以前的YOLO博文中，我使用<a href="https://github.com/allanzelener/YAD2K" target="_blank" rel="external">YAD2K</a>从Darknet转换为<a href="https://github.com/allanzelener/YAD2K" target="_blank" rel="external">Keras</a> 2.0。但是，Core ML转换工具只支持Keras 1.2.2版本。所以首先我需要修改YAD2K脚本来使用旧版本的Keras（这个被改过的YAD2K被包含在YAD2K github repo中）。</p>
<p>您可以在README文件中找到有关如何进行此转换的<a href="https://github.com/hollance/YOLO-CoreML-MPSNNGraph/blob/master/README.markdown" target="_blank" rel="external">完整说明</a>。</p>
<p>Darknet-to-Keras转换成功之后，会生成一个<strong>tiny-yolo-voc.h5</strong>文件（在<strong>yad2k / model_data /</strong>目录中）。这是我们在以前的博客文章中使用的模型完全相同，但与Keras 1.2.2兼容。</p>
<blockquote>
<p>YAD2K-<a href="https://github.com/allanzelener/YAD2K" target="_blank" rel="external">https://github.com/allanzelener/YAD2K</a></p>
<p>完整说明-<a href="https://github.com/hollance/YOLO-CoreML-MPSNNGraph/blob/master/README.markdown" target="_blank" rel="external">https://github.com/hollance/YOLO-CoreML-MPSNNGraph/blob/master/README.markdown</a></p>
</blockquote>
<h3 id="步骤2：Keras-1-2-2到-Core-ML"><a href="#步骤2：Keras-1-2-2到-Core-ML" class="headerlink" title="步骤2：Keras 1.2.2到 Core ML"></a>步骤2：Keras 1.2.2到 Core ML</h3><p>现在Core ML转换工具支持YOLO格式，我们可以编写一个Python脚本，将其转换成我们需要的<strong>.mlmodel</strong>文件。</p>
<p><strong>注意：</strong>如果您只想运行演示应用程序，则不需要执行这些步骤。最终的TinyYOLO.mlmodel文件已经包含在repo中。之所以提这些步骤，是说明下如何做模型转换。如果你想在你<strong>自己的应用程序</strong>中使用预先训练的模型，那就是你必须要亲自手动尝试下。</p>
<p>Core ML转换工具需要在<code>/usr/bin/python</code>目录下的Python 2.7（macOS已默认安装了），而其他版本的Python会有问题。</p>
<p>由于还需要安装一些软件包，因此最好制作一个“virtualenv”或虚拟环境。我会解释下一步怎么做。</p>
<p>首先，确保安装了Xcode 9 beta版，并设置<code>xcode-select</code>来使用这个beta版。从终端运行此命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo xcode-select --switch /Applications/Xcode-beta.app/Contents/Developer</div></pre></td></tr></table></figure>
<p>还要确保你已经<code>pip</code>安装。这是Python包管理器，您将使用它来安装其他软件包：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo easy_install pip</div></pre></td></tr></table></figure>
<p>接下来，安装<code>virtualenv</code>包：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install -U virtualenv</div></pre></td></tr></table></figure>
<p>好的，这些都是我们要用到的包。现在我们可以为Core ML创建一个虚拟环境。我们要把所有Python包装到这个虚拟环境 - 这样和其他版本的python相隔离，不会影响其他版本的python包。这可以让我们在同一个系统上运行不同版本的Python和Keras。</p>
<p>在这里，我们将虚拟环境放在home文件夹（<code>~</code>或<code>/Users/yourname</code>）中，但您可以将其放在任何你喜欢的地方（只是装完后不要随便移动，否则会导致异常）。</p>
<p>运行如下命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd ~</div><div class="line">virtualenv -p /usr/bin/python2.7 coreml</div></pre></td></tr></table></figure>
<p>该<code>-p</code>标志告诉virtualenv使用<strong>系统版本</strong>的Python 2.7。正如我在上面指出的，这是至关重要的。如果您使用另一个Python版本（即使是2.7，必须是系统自带的版本），则coremltools包将给出错误。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">source coreml/bin/activate</div></pre></td></tr></table></figure>
<p>这将激活刚刚创建的virtualenv。你会看到终端提示<code>(coreml)</code>，这会告诉你你目前所处的环境。（要返回正常环境，可以键入命令<code>deactivate</code>）</p>
<p>现在我们可以安装我们需要的软件包：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">pip install tensorflow</div><div class="line">pip install keras==1.2.2</div><div class="line">pip install h5py</div><div class="line">pip install coremltools</div></pre></td></tr></table></figure>
<p>这些软件包将被安装在<code>~/coreml/lib/python2.7/site-packages/</code>。安装完毕了。现在可以运行<strong>coreml.py</strong>转换脚本（请参阅在repo中<strong>转换</strong>文件夹）。这会读取<strong>tiny-yolo-voc.h5 Keras</strong>模型，在<strong>TinyYOLO-CoreML</strong>项目的文件夹中，生成<strong>TinyYOLO.mlmodel</strong>。</p>
<p><strong>coreml.py</strong>脚本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">import coremltools</div><div class="line"></div><div class="line">coreml_model = coremltools.converters.keras.convert(</div><div class="line">    &apos;yad2k/model_data/tiny-yolo-voc.h5&apos;,</div><div class="line">        input_names=&apos;image&apos;,</div><div class="line">            image_input_names=&apos;image&apos;,</div><div class="line">                output_names=&apos;grid&apos;,</div><div class="line">                    image_scale=1/255.)</div><div class="line"></div><div class="line">coreml_model.input_description[&apos;image&apos;] = &apos;Input image&apos;</div><div class="line">coreml_model.output_description[&apos;grid&apos;] = &apos;The 13x13 grid&apos;</div><div class="line"></div><div class="line">coreml_model.save(&apos;../TinyYOLO-CoreML/TinyYOLO-CoreML/TinyYOLO.mlmodel&apos;)</div></pre></td></tr></table></figure>
<p>这是一个非常简单的脚本，但在调用<code>coremltools.converters.keras.convert()</code>时，设定对的参数很重要。</p>
<p>YOLO需要输入图像的像素为0和1，而不是0和255之间，所以我们必须以指定<code>image_scale</code>为<code>1/255</code>。不需要对输入图像进行任何其他预处理。</p>
<p>您不需要自己运行此转换脚本，因为repo已经包含<strong>TinyYOLO.mlmodel</strong>文件，但如果您好奇，想试试，运行如下命令即可：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd Convert</div><div class="line">python coreml.py</div></pre></td></tr></table></figure>
<p>该脚本输出一堆关于转换过程的信息。最后打印出模型的输出。看起来像这样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">input &#123;</div><div class="line">          name: &quot;image&quot;</div><div class="line">            shortDescription: &quot;Input image&quot;</div><div class="line">              type &#123;</div><div class="line">                          imageType &#123;</div><div class="line">                                        width: 416</div><div class="line">                                              height: 416</div><div class="line">                                                    colorSpace: RGB</div><div class="line">                                                        &#125;</div><div class="line">                                                          &#125;</div><div class="line">&#125;</div><div class="line">output &#123;</div><div class="line">          name: &quot;grid&quot;</div><div class="line">            shortDescription: &quot;The 13x13 grid&quot;</div><div class="line">              type &#123;</div><div class="line">                          multiArrayType &#123;</div><div class="line">                                        shape: 125</div><div class="line">                                              shape: 13</div><div class="line">                                                    shape: 13</div><div class="line">                                                          dataType: DOUBLE</div><div class="line">                                                              &#125;</div><div class="line">                                                                &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>显示YOLO需要大小为416×416像素的RGB图像。</p>
<p>该神经网络产生的输出是形状为125×13×13的“多数组”。这就说得通了。如你所知，YOLO的最后一层输出一个13×13个单元格，每个单元格包含125个数字，包含5个边界框的预测。</p>
<p><strong>注意：</strong>转换脚本调用<code>coremltools.converters.keras.convert()</code>时不指定<code>class_labels</code>参数。当您指定<code>class_labels</code>时，转换器创建一个模型，输出一个字典<code>(String, Double)</code>与模型训练的类的<strong>概率</strong>。但是YOLO不是分类器。通过省略<code>class_labels</code>参数，转换工具不会以任何方式去计算最后一层的概率分布，我们直接访问最后一层的输出（feature map）。</p>
<p>太棒了！我们终于有一个<strong>TinyYOLO.mlmodel</strong>文件，我们可以安装到应用程序了。</p>
<h3 id="步骤3：将模型添加到应用程序"><a href="#步骤3：将模型添加到应用程序" class="headerlink" title="步骤3：将模型添加到应用程序"></a>步骤3：将模型添加到应用程序</h3><p>将Core ML模型添加到您的应用程序很简单：<a href="http://machinethink.net/blog/ios-11-machine-learning-for-everyone/" target="_blank" rel="external">只需将其拖放</a>到Xcode项目中即可。然后，Xcode将生成一些代码，使其很容易使用模型。</p>
<blockquote>
<p><a href="http://machinethink.net/blog/ios-11-machine-learning-for-everyone/" target="_blank" rel="external">http://machinethink.net/blog/ios-11-machine-learning-for-everyone/</a>)</p>
</blockquote>
<p>在我们的案例中，Xcode已经生成了<strong>TinyYOLO.swift</strong>。此文件不会显示在项目文件导航器中，但可以单击<strong>TinyYOLO.mlmodel，</strong>并从中查看此源文件。</p>
<p>我们大部分都是讲解<code>TinyYOLO</code>类：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">@objc class TinyYOLO:NSObject &#123;</div><div class="line">            func prediction(image: CVPixelBuffer) throws -&gt; TinyYOLOOutput &#123;</div><div class="line">                            let input_ = TinyYOLOInput(image: image)</div><div class="line">                                    return try self.prediction(input: input_)</div><div class="line">                                        &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个类还有很多代码，我可以暂不关心。我们关心的是<code>prediction(image)</code>方法。此方法输入<code>CVPixelBuffer</code>（一个包含图像的对象）并返回一个<code>TinyYOLOOutput</code>对象。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">class TinyYOLOOutput : MLFeatureProvider &#123;</div><div class="line">            let grid: MLMultiArray</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个类的相关部分是<code>MLMultiArray</code>对象。它包含13×13网格的边框预测。（该属性被称作<code>grid</code>，是因为我们在转换脚本中，使用<code>output_names=&#39;grid&#39;</code>这个参数指定了该属性。）</p>
<p>理想情况下，我们不会<code>TinyYOLO</code>直接使用这个类，而是通过Vision框架。不幸的是，我无法让它工作（在beta 1和2中）。</p>
<p>我们希望Vision给我们一个<code>VNCoreMLFeatureValueObservation</code>对象，此对象有个<code>MLMultiArray</code>子对象（有13×13网格）。但是目前，Vision并没有为这个Core ML模型返回<em>任何东西</em>。我的猜测是，在当前的测试版中不支持非分类器。</p>
<p>所以现在我们别无选择，只能跳过Vision并直接使用Core ML。这意味着我们需要将输入图像存入<code>CVPixelBuffer</code>这个缓冲区对象中，并将这个缓冲区的大小调整到416×416像素，否则Core ML将不会接受它。</p>
<p>得到一个<code>CVPixelBuffer</code>并不重要，因为我们使用AVFoundation来捕获实况视频，调用<code>AVCaptureVideoDataOutput</code>，可以简单地执行以下操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">public func captureOutput(_ output: AVCaptureOutput,</div><div class="line">                          didOutput sampleBuffer: CMSampleBuffer, </div><div class="line">                                                    from connection: AVCaptureConnection) &#123;</div><div class="line"></div><div class="line">          let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer)</div><div class="line">            // give the imageBuffer to Core ML ...</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>该<code>CMSampleBufferGetImageBuffer()</code>功能是，把<code>CMSampleBuffer</code>（包含相机像素数据的缓冲区）对象，转换为<code>CVPixelBuffer</code>。</p>
<p>但是，相机返回480×640图像，而不是416×416，所以我们必须调整相机输出的大小。不用担心，Core Image 有相关函数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">let ciImage = CIImage(cvPixelBuffer: pixelBuffer)</div><div class="line">let sx = 416 / CGFloat(CVPixelBufferGetWidth(pixelBuffer))</div><div class="line">let sy = 416 / CGFloat(CVPixelBufferGetHeight(pixelBuffer))</div><div class="line">let scaleTransform = CGAffineTransform(scaleX: sx, y: sy)</div><div class="line">let scaledImage = ciImage.applying(scaleTransform)</div><div class="line">ciContext.render(scaledImage, to: resizedPixelBuffer)</div></pre></td></tr></table></figure>
<p>由于相机的图像高度大于宽度，所以会使图像稍微变形一些。这对于这个应用程序来说不算什么，但是可以使用Core Image在调整大小之前先裁剪中心正方形。</p>
<p>现在我们有一个<code>CVPixelBuffer</code>416×416的图像，我们可以预测这个图像了。</p>
<p><strong>注意：</strong> 另一种调整图像大小的方法是，调用Accelerate框架中<code>vImageScale_ARGB8888()</code>。这段代码也在演示应用程序中，但它比使用Core Image工作量要大。</p>
<h3 id="步骤4：预测"><a href="#步骤4：预测" class="headerlink" title="步骤4：预测"></a>步骤4：预测</h3><p>Core ML的预测很简单：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">let model = TinyYOLO()</div><div class="line"></div><div class="line">let image: CVPixelBuffer = ...</div><div class="line"></div><div class="line">if let output = try? model.prediction(image: image) &#123;</div><div class="line">          // do something with output.grid</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>model.prediction(image)</code>输出是<code>MLMultiArray</code>，描述了13×13网格的输出。</p>
<p><strong>注意：</strong> <code>MLMultiArray</code>有点像<a href="http://www.numpy.org/" target="_blank" rel="external">NumPy数组，</a>但其他功能很少。例如，没有办法转置轴或将矩阵重新形成不同的维度。</p>
<p>现在我们如何将<code>MlMultiArray</code>的边框，显示在应用程序中？</p>
<p><code>MLMultiArray</code>对象为125×13×13。13×13网格中的每个单元格共有125个通道，因为每个单元格预测5个边界框，每个边界框由25个数字描述：</p>
<ul>
<li>4个矩形坐标值</li>
<li>1个预测的概率值（例如“我是75.3％肯定这是一只狗”）</li>
<li>top-20 概率分布</li>
</ul>
<p>该<code>computeBoundingBoxes()</code>函数将<code>MLMultiArray</code>转换为可以在屏幕上绘制的边框列表。用到的数学知识与<a href="http://machinethink.net/blog/object-detection-with-yolo/" target="_blank" rel="external">前一篇博客文章的</a> 100％一样，所以我建议您读下那个博客了解下细节。</p>
<blockquote>
<p><a href="http://machinethink.net/blog/object-detection-with-yolo/" target="_blank" rel="external">http://machinethink.net/blog/object-detection-with-yolo/</a></p>
</blockquote>
<p>不用显示整个函数，只突出显示与Metal版本不同的部分：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">public func computeBoundingBoxes(features: MLMultiArray) -&gt; [Prediction] &#123;</div><div class="line"></div><div class="line">          for cy in 0..&lt;13 &#123;</div><div class="line">                      for cx in 0..&lt;13 &#123;</div><div class="line">                                    for b in 0..&lt;5 &#123;</div><div class="line"></div><div class="line">                                                    // Look at bounding box b for the grid cell (cy, cx):</div><div class="line">                                                            let channel = b*(numClasses + 5)</div><div class="line">                                                                    let tx = features[[channel    , cy, cx] as [NSNumber]].floatValue</div><div class="line">                                                                            let ty = features[[channel + 1, cy, cx] as [NSNumber]].floatValue</div><div class="line">                                                                                    let tw = features[[channel + 2, cy, cx] as [NSNumber]].floatValue</div><div class="line">                                                                                            let th = features[[channel + 3, cy, cx] as [NSNumber]].floatValue</div><div class="line">                                                                                                    let tc = features[[channel + 4, cy, cx] as [NSNumber]].floatValue</div><div class="line"></div><div class="line">                                                                                                            . . .</div><div class="line">                                                                                                                  &#125;</div><div class="line">                                                                                                                      &#125;</div><div class="line">                                                                                                                        &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>要获得一个边界框坐标<code>tx</code>，<code>ty</code>，<code>tw</code>，<code>th</code>和置信度得分<code>tc</code>，可以用下标索引遍历<code>MLMultiArray</code>。不幸的是，我们不能简单地写：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">let tx = features[channel, cy, cx]</div></pre></td></tr></table></figure>
<p>因为<code>MLMultiArray</code>是一个Objective-C对象，我们需要将索引包装在一个<code>NSNumber</code>类型的数组中。结果也是<code>NSNumber</code>类型，所以我们需要<code>.floatValue</code>用来把它改成一个<code>Float</code>。</p>
<p>我希望这可以在以后的betas中得到简化 - <code>NSNumber</code>调用方式并不优雅。</p>
<p><strong>注意：</strong>使用正确的顺序索引多数组很重要。最初我写了<code>features[[channel, cx, cy]]</code>，然后所有的边框都反了。浪费了一些时间才想明白…注意Core ML放入数据的顺序！</p>
<h3 id="步骤5：试试吧！"><a href="#步骤5：试试吧！" class="headerlink" title="步骤5：试试吧！"></a>步骤5：试试吧！</h3><p>嗯，让YOLO运行在Core ML确实需要点时间。但是，一旦完成了模型转换，预测就很容易了。</p>
<p>对于YOLO，只做预测是不够的。我们仍然需要对模型的输出进行一些额外的处理，需要操作<code>MLMultiArray</code>类。</p>
<p><a href="http://machinethink.net/images/yolo-coreml-mps-graph/Eagle@2x.png" target="_blank" rel="external"><img src="http://machinethink.net/images/yolo-coreml-mps-graph/Eagle.png" alt="小YOLO发现一只鸟"></a></p>
<h2 id="YOLO与MPSNNGraph"><a href="#YOLO与MPSNNGraph" class="headerlink" title="YOLO与MPSNNGraph"></a>YOLO与MPSNNGraph</h2><p>当你想跳过Core ML，或者当Core ML不支持你的模型类型 - 或者你只是想折腾 - 可以尝试下<strong>Metal</strong>。</p>
<p><strong>注意：</strong>对于小型模型，如Logistic回归，Accelerate框架是一种比Metal更好的选择。在这里，我假设你想做深度学习。</p>
<p>在iOS 11中，现在有两种方法可以使用Metal Performance Shader来进行机器学习：</p>
<ol>
<li>自己创建MPSCNN并将它们编码到commandBuffer（参见我的<a href="http://machinethink.net/blog/convolutional-neural-networks-on-the-iphone-with-vggnet/" target="_blank" rel="external">VGGNet帖子</a>一个例子）</li>
<li>使用新的图形API描述您的神经网络，并让图形接口处理所有内容</li>
</ol>
<blockquote>
<p><a href="http://machinethink.net/blog/convolutional-neural-networks-on-the-iphone-with-vggnet" target="_blank" rel="external">http://machinethink.net/blog/convolutional-neural-networks-on-the-iphone-with-vggnet</a></p>
</blockquote>
<p>在博文的第二部分，我们将看看这个新的graph API。</p>
<p>代码是在<strong>TinyYOLO-NNGraph</strong>项目中，接下来打开这个项目。</p>
<h3 id="步骤1：转换模型"><a href="#步骤1：转换模型" class="headerlink" title="步骤1：转换模型"></a>步骤1：转换模型</h3><p>是的，它也需要做一些转换。我们再次使用由YAD2K创建的Keras 1.2.2模型。（您可以使用Keras 2.0，因为我已经为Core ML制作了一个1.2.2模型，我们就使用它吧。）</p>
<p>在<a href="http://machinethink.net/blog/object-detection-with-yolo/" target="_blank" rel="external">之前的YOLO帖子中，</a>我们创建了一个转换脚本，将批量归一化参数“折叠”成卷积层的权重。必须这样做，因为Metal没有批量归一化层。</p>
<blockquote>
<p><a href="http://machinethink.net/blog/object-detection-with-yolo/" target="_blank" rel="external">http://machinethink.net/blog/object-detection-with-yolo/</a>)</p>
</blockquote>
<p>虽然MPS没有batch normalization 层，但MPS 可以通过“折叠”来做batch norm。所以这样就可以更简单地进行转换。</p>
<p>您可以在<strong>nngraph.py中</strong>看到相关代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">import os</div><div class="line">import numpy as np</div><div class="line">import keras</div><div class="line">from keras.models import Sequential, load_model</div><div class="line"></div><div class="line">model_path = &quot;yad2k/model_data/tiny-yolo-voc.h5&quot;</div><div class="line">dest_path = &quot;../TinyYOLO-NNGraph/Parameters&quot;</div><div class="line"></div><div class="line">model = load_model(model_path)</div><div class="line"></div><div class="line">def export_conv_and_batch_norm(conv_layer, bn_layer, name):</div><div class="line">    bn_weights = bn_layer.get_weights()</div><div class="line">        gamma = bn_weights[0]</div><div class="line">            beta = bn_weights[1]</div><div class="line">                mean = bn_weights[2]</div><div class="line">                    variance = bn_weights[3]</div><div class="line"></div><div class="line">                        conv_weights = conv_layer.get_weights()[0]</div><div class="line">                            conv_weights = conv_weights.transpose(3, 0, 1, 2).flatten()</div><div class="line"></div><div class="line">                                combined = np.concatenate([conv_weights, mean, variance, gamma, beta])</div><div class="line">                                    combined.tofile(os.path.join(dest_path, name + &quot;.bin&quot;))</div><div class="line"></div><div class="line">                                    export_conv_and_batch_norm(model.layers[1], model.layers[2], &quot;conv1&quot;)</div><div class="line">                                    export_conv_and_batch_norm(model.layers[5], model.layers[6], &quot;conv2&quot;)</div><div class="line"># and so on for the other layers ...</div></pre></td></tr></table></figure>
<pre><code>首先加载我们用YAD2K制作的**tiny-yolo-voc.h5**模型。

然后，它遍历所有卷积层，并将权重与批次正则化参数一起放入单个文件中，每个层一个文件。这样做不是必须的，而且还会有大量的小文件。但这使得在应用程序中更容易加载这些数据。

运行转换脚本后，我们现在有**conv1.bin**，**conv2.bin等**文件。这些文件放置在**TinyYOLO-NNGraph / Parameters**文件夹中，并在构建应用程序时通过Xcode复制到应用程序包中。
</code></pre><h3 id="步骤2：将模型添加到应用程序"><a href="#步骤2：将模型添加到应用程序" class="headerlink" title="步骤2：将模型添加到应用程序"></a>步骤2：将模型添加到应用程序</h3><p>MPSCNN API的一个重大变化是，当创建一个新层时，不再直接传入<code>MPSCNNConvolutionDescriptor</code>，也不会初始化权重。</p>
<p>相反，你需要传入<code>MPSCNNConvolutionDataSource</code>对象。该对象负责加载权重。</p>
<p>我们开始写数据输入类。由于我们的层都非常相似，所以我们<code>DataSource</code>将为所有层使用相同的类 - 但是每个层都有自己的实例。代码如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">class DataSource: NSObject, MPSCNNConvolutionDataSource &#123;</div><div class="line">          let name: String</div><div class="line">            let kernelWidth: Int</div><div class="line">              let kernelHeight: Int</div><div class="line">                let inputFeatureChannels: Int</div><div class="line">                  let outputFeatureChannels: Int</div><div class="line">                    let useLeaky: Bool</div><div class="line"></div><div class="line">                      var data: Data?</div><div class="line"></div><div class="line">                        func load() -&gt; Bool &#123;</div><div class="line">                                    if let url = Bundle.main.url(forResource: name, withExtension: &quot;bin&quot;) &#123;</div><div class="line">                                                  do &#123;</div><div class="line">                                                                  data = try Data(contentsOf: url)</div><div class="line">                                                                          return true</div><div class="line">                                                                                &#125; catch &#123;</div><div class="line">                                                                                                print(&quot;Error: could not load \(url): \(error)&quot;)</div><div class="line">                                                                                                      &#125;</div><div class="line">                                                                                                          &#125;</div><div class="line">                                                                                                              return false</div><div class="line">                                                                                                                &#125;</div><div class="line"></div><div class="line">                                                                                                                  func purge() &#123;</div><div class="line">                                                                                                                              data = nil</div><div class="line">                                                                                                                                &#125;</div><div class="line"></div><div class="line">                                                                                                                                  func weights() -&gt; UnsafeMutableRawPointer &#123;</div><div class="line">                                                                                                                                              return UnsafeMutableRawPointer(mutating: (data! as NSData).bytes)</div><div class="line">                                                                                                                                                &#125;</div><div class="line"></div><div class="line">                                                                                                                                                  func biasTerms() -&gt; UnsafeMutablePointer&lt;Float&gt;? &#123;</div><div class="line">                                                                                                                                                              return nil</div><div class="line">                                                                                                                                                                &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>该<code>MPSCNNConvolutionDataSource</code>需要具有<code>load()</code>和<code>purge()</code>函数。在这里，我们只需将上一步导出的二进制文件（例如，<strong>conv1.bin</strong>）<strong>加载</strong>到<code>Data</code>对象中即可。</p>
<p>要获取此层的权重，该<code>weights()</code>函数将返回一个指向此<code>Data</code>对象的第一个元素的指针。我们的层没有偏置，所以<code>biasTerms()</code>可以返回<code>nil</code>（在使用批量正则时，因为“beta”参数已经作为偏置项了）。</p>
<p><code>DataSource</code>类有趣部分是返回<code>MPSCNNConvolutionDescriptor</code>对象的函数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">func descriptor() -&gt; MPSCNNConvolutionDescriptor &#123;</div><div class="line">          let desc = MPSCNNConvolutionDescriptor(</div><div class="line">                             kernelWidth: kernelWidth,</div><div class="line">                                                kernelHeight: kernelHeight,</div><div class="line">                                                                   inputFeatureChannels: inputFeatureChannels,</div><div class="line">                                                                                      outputFeatureChannels: outputFeatureChannels)</div><div class="line"></div><div class="line">            desc.neuronType = .reLU</div><div class="line">              desc.neuronParameterA = 0.1</div><div class="line"></div><div class="line">                data?.withUnsafeBytes &#123; (ptr: UnsafePointer&lt;Float&gt;) -&gt; Void in</div><div class="line">                    let weightsSize = outputFeatureChannels * kernelHeight * </div><div class="line">                                          kernelWidth * inputFeatureChannels</div><div class="line">                                                                </div><div class="line">                                                                    let mean = ptr.advanced(by: weightsSize)</div><div class="line">                                                                        let variance = mean.advanced(by: outputFeatureChannels)</div><div class="line">                                                                            let gamma = variance.advanced(by: outputFeatureChannels)</div><div class="line">                                                                                let beta = gamma.advanced(by: outputFeatureChannels)</div><div class="line">                                                                                    </div><div class="line">                                                                                        desc.setBatchNormalizationParametersForInferenceWithMean(mean,</div><div class="line">                                                                                                    variance: variance, gamma: gamma, beta: beta, epsilon: 1e-3)</div><div class="line">                                                                                          &#125;</div><div class="line"></div><div class="line">                                                                                            return desc</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>使用iOS 10，可以将一个<code>MPSCNNNeuron</code>对象赋给给descriptor的<code>neuron</code>属性。但现在已经被弃用了，你应该使用<code>neuronType</code>枚举。这里我们要使用一个“leaky”ReLU，所以我们也把值设置<code>neuronParameterA</code>为0.1。</p>
<p><code>setBatchNormalizationParametersForInferenceWithMean()</code>函数也是新的。这使得处理<strong>批量正则</strong>比以前容易得多。我们还在<code>Data</code>对象中存储mean，variance，gamma和β，通过设置正确的<code>UnsafePointer</code>，然后调用该方法。</p>
<p>MPS将自动处理<strong>批量正则化</strong>，我们不必再担心了。太好了！</p>
<p>现在，数据源被整理出来，我们可以开始构建图：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">let inputImage = MPSNNImageNode(handle: nil)</div><div class="line"></div><div class="line">let scale = MPSNNLanczosScaleNode(source: inputImage,</div><div class="line">                 outputSize: MTLSize(width: 416, height: 416, depth: 3))</div><div class="line"></div><div class="line">let conv1 = MPSCNNConvolutionNode(source: scale.resultImage,</div><div class="line">                                  weights: DataSource(&quot;conv1&quot;, 3, 3, 3, 16))</div><div class="line"></div><div class="line">let pool1 = MPSCNNPoolingMaxNode(source: conv1.resultImage, filterSize: 2)</div><div class="line"></div><div class="line">let conv2 = MPSCNNConvolutionNode(source: pool1.resultImage,</div><div class="line">                                  weights: DataSource(&quot;conv2&quot;, 3, 3, 16, 32))</div><div class="line"></div><div class="line">let pool2 = MPSCNNPoolingMaxNode(source: conv2.resultImage, filterSize: 2)</div><div class="line"></div><div class="line">// ... and so on ...</div><div class="line"></div><div class="line">guard let graph = MPSNNGraph(device: device, </div><div class="line">                             resultImage: conv9.resultImage) else &#123;</div><div class="line">                                       fatalError(&quot;Error: could not initialize graph&quot;)</div><div class="line">                             &#125;</div></pre></td></tr></table></figure>
<pre><code>我们首先为输入图像声明一个节点，并将一个将该输入图像缩放到416×416。接下来每个层都使用`source`参数连接到前一个层。所以`scale`节点连接到`inputImage`，`conv1`被连接到`scale.resultImage`，等等。graph本身是一个`MPSNNGraph`对象，并连接到网络中最后一层的输出`conv9`。

如果您以前使用过MPSCNN，您会注意到，搭建神经网络并不复杂。然而，一些复杂性已被移动到您的`Data`对象中。如果你有一个复杂的网络，那么你最终可能会写几个不同的`Data`类。

在我第一次使用图形API实现YOLO之后，我尝试运行应用程序，所有的边框看起来都是正确的 - 除了它们向下移动和向右移动32像素。WTH？经过一系列的调试，结果发现层**pool6**上的填充（padding）错误。

这个**pool6**层与其他池层不同，因为它使用stride 1而不是stride 2.因此它需要不同类型的填充（padding）。要更改层的填充方式，需要`paddingPolicy`在节点上设置属性。像这样：

<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">pool6.paddingPolicy = MPSNNDefaultPadding(method: </div><div class="line">                   [.alignTopLeft, .addRemainderToBottomRight, .sizeSame])</div></pre></td></tr></table></figure>

默认情况下，填充设为`.alignCentered`而不是`.alignTopLeft`。这就造成了池化层的输出不完全正确，特别是在图像的右侧和底部。

图像已经缩小到13×13像素，由于filter是2×2，因此在图像的右下边缘需要一个像素的填充。

事实证明，在我以前的实现中，我已经将填充kernel的边缘设置为“clamp”而不是“zero”。使用&apos;&apos;zero&quot;，它会在图像的边缘（duh）加零填充，但是用&quot;clamp&quot;会复制边缘图像进行填充。（“clamp&quot;比较适合max-pooling，尤其当值是负数的时候）。

使用graph API，无法让max-pooling层使用“clamp&quot;填充。为此，必须编写自己的`MPSNNPadding`类。

现在，YOLO可能会以零填充而不是“clamp”填充，但是由于整个练习是更好地了解graph API，所以让我们自己实现填充类。看起来像这样：

<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">class Pool6Padding: NSObject, MPSNNPadding &#123;</div><div class="line">          func paddingMethod() -&gt; MPSNNPaddingMethod &#123;</div><div class="line">                      return [ .custom, .sizeSame ]</div><div class="line">                        &#125;</div><div class="line"></div><div class="line">                          func destinationImageDescriptor(</div><div class="line">                                            forSourceImages sourceImages: [MPSImage],</div><div class="line">                                                              sourceStates: [MPSState]?,</div><div class="line">                                                                                for kernel: MPSKernel,</div><div class="line">                                                                                                          suggestedDescriptor inDescriptor: MPSImageDescriptor) </div><div class="line">                                            -&gt; MPSImageDescriptor &#123;</div><div class="line">                                                        if let kernel = kernel as? MPSCNNPooling &#123;</div><div class="line">                                                                      kernel.offset = MPSOffset(x: 1, y: 1, z: 0)</div><div class="line">                                                                            kernel.edgeMode = .clamp</div><div class="line">                                                                                &#125;</div><div class="line">                                                                                    return inDescriptor</div><div class="line">                                                                                      &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>

`NSCoding`以便您可以将图表序列化到文件，还有重要一点，在`paddingMethod()`我们返回`.custom`。这将使MPS调用`destinationImageDescriptor(...)`此函数。

在这个函数内部，我们可以访问底层`MPSCNNPooling`对象，以便我们可以设置其`offset`属性以获取`.alignTopLeft`行为，并将其设置`edgeMode`为`.clamp`。

现在，该graph computes 能得到与Forge版本完全相同的结果了。😀
</code></pre><h3 id="步骤3：预测"><a href="#步骤3：预测" class="headerlink" title="步骤3：预测"></a>步骤3：预测</h3><p>使用Core ML，输入图像必须是一个<code>CVPixelBuffer</code>，但Metal需要<code>MTLTexture</code>。在相机代码中，我们可以轻松地将相机中的像素转换为texture：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">if let imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) &#123;</div><div class="line">          let width = CVPixelBufferGetWidth(imageBuffer)</div><div class="line">            let height = CVPixelBufferGetHeight(imageBuffer)</div><div class="line"></div><div class="line">              var texture: CVMetalTexture?</div><div class="line">                CVMetalTextureCacheCreateTextureFromImage(kCFAllocatorDefault, textureCache,</div><div class="line">                         imageBuffer, nil, .bgra8Unorm, width, height, 0, &amp;texture)</div><div class="line"></div><div class="line">                  if let texture = texture &#123;</div><div class="line">                              let textureFromCamera = CVMetalTextureGetTexture(texture)</div><div class="line">                                  // do a prediction using this texture...</div><div class="line">                                    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>一旦你拥有这个texture，你只需要做以下的事情进行预测：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">let inputImage = MPSImage(texture: textureFromCamera, featureChannels: 3)</div><div class="line"></div><div class="line">graph.executeAsync(withSourceImages: [inputImage]) &#123; outputImage, error in</div><div class="line">  if let image = outputImage &#123;</div><div class="line">              self.computeBoundingBoxes(image)</div><div class="line">                &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>该<code>executeAsync()</code>函数会在幕后处理所有Metal对象，并通知你何时完成。</p>
<p>我们调用<code>computeBoundingBoxes()</code>。这个方法和我以前的Metal实现的YOLO完全一样，所以我建议你<a href="http://machinethink.net/blog/object-detection-with-yolo/" target="_blank" rel="external">阅读这篇博客文章</a>来了解。</p>
<blockquote>
<p><a href="http://machinethink.net/blog/object-detection-with-yolo/" target="_blank" rel="external">http://machinethink.net/blog/object-detection-with-yolo/</a></p>
</blockquote>
<p><strong>6月22日更新：</strong>在beta 1中没有<code>MPSNNLanczosScaleNode</code>，这意味着Metal不知道输入图像应该有多大。显然<code>MPSNNGraph</code>不需要知道这些信息，它会接受任何大小的图像。这很好，但是我们的特定神经网络输入图像必须是416×416像素 ，如果不是，我们将得不到13×13像素的网格。在beta2<br>中<code>MPSNNLanczosScaleNode</code>和<code>MPSNNBilinearScaleNode</code>解决了这个问题。</p>
<p>如果流有很多不需要自定义的kernels，那么您可以自己将graph编码为command buffer：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">let commandBuffer = commandQueue.makeCommandBuffer()</div><div class="line"></div><div class="line">// Run your own compute kernel for preprocessing</div><div class="line">let myImageDesc = MPSImageDescriptor(...)</div><div class="line">let myImage = MPSTemporaryImage(commandBuffer: commandBuffer, </div><div class="line">                                imageDescriptor: myImageDesc)</div><div class="line">myComputeKernel.encode(commandBuffer: commandBuffer,</div><div class="line">                       sourceTexture: textureFromCamera, </div><div class="line">                                              destinationTexture: myImage.texture)</div><div class="line"></div><div class="line">// Run the graph</div><div class="line">let graphImg = graph.encode(to: commandBuffer, sourceImages: [myImage])</div><div class="line"></div><div class="line">// Run your own postprocessing kernel</div><div class="line">// ...</div><div class="line"></div><div class="line">// This is called when the graph is finished</div><div class="line">commandBuffer.addCompletedHandler &#123; commandBuffer in</div><div class="line">  // ...</div><div class="line">&#125;</div><div class="line"></div><div class="line">commandBuffer.commit()</div></pre></td></tr></table></figure>
<p>这样，您可以在graph之前或之后运行自己的compute kernels。</p>
<h3 id="步骤4：试试吧！"><a href="#步骤4：试试吧！" class="headerlink" title="步骤4：试试吧！"></a>步骤4：试试吧！</h3><p>运行应用程序，可以看到结果与Core ML版本完全相同。没有什么大惊喜，因为核心ML底层使用的Metal。</p>
<p><a href="http://machinethink.net/images/yolo-coreml-mps-graph/Person@2x.png" target="_blank" rel="external"><img src="http://machinethink.net/images/yolo-coreml-mps-graph/Person.png" alt="小YOLO有时会犯错误"></a></p>
<p><strong>注意：</strong>运行这些类型的神经网络会消耗严重的电池电量。这就是为什么演示应用程序限制运行模型的频率。你可以<code>setUpCamera()</code>用这一行来改变它<code>videoCapture.fps = 5</code>。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>我希望这篇博文可以让您深入了解使用Core ML和Metal的图形API之间的区别。</p>
<p>至于速度差异，这<em>不</em>是重要的。这两个应用程序性能都差不多。然而，在beta 1中，Core ML版本非常慢。（我相信这会很快好起来的，因为早期的betas总是在缓慢的优化中。）</p>
<p>两种API之间的巨大区别在于易用性。使用Core ML，可以很容易让model上线。而<code>MPSNNGraph</code>复杂一些，你需要更多地了解模型的内部。但是，与“老式”MPS相比，这两者使用起来都容易得多。</p>
<p>Core ML最大的缺点是对模型运行时缺少灵活的控制。但说实话，甚至<code>MPSNNGraph</code>也并不能给你很多选择：</p>
<ul>
<li>很难理解graph中发生了什么。可以<code>print(graph.debugDescription)</code>查看图中的节点，以及填充方法等等。<del>但是，似乎没有办法检查图形自动产生的图像大小。</del></li>
</ul>
<p><strong>6月22日更新：</strong>如果您设置，<code>graph.options = .verbose</code>则图形将打印出图像的大小。这在beta 1中并不支持，但在beta 2中，可以设置<code>MPS_LOG_INFO</code>环境变量来解决这个问题。)</p>
<ul>
<li>您不能扩展graph API以添加自定义kernel。可以在graph之前或之后运行自定义kernel，或者将图形分为两部分，并在中间进行自己的kernel。但是，如果要在整个网络中使用自定义kernel，则graphAPI无法帮助您。</li>
</ul>
<p>最后一点是一个主要的缺点。使用Core ML，需依赖<strong>mlmodel</strong>格式规范 - 如果模型某些部分，Core ML并不支持，则不能使用此API。<code>MPSNNGraph</code>也一样：如果你的模型需要做一些不包括在MPS中的东西，那么你不能使用图形API。</p>
<p>当你有一个简单的模型，或者想要使用一个久经考验的深入学习模型时，我认为Core ML是一个很好的解决方案。</p>
<p>但是，如果你想做一些深度学习的前沿模型，那么你必须使用底层api和Metal。这意味着您需要使用自定义计算kernel，所以<code>MPSNNGraph</code>也不能用。你仍然可以使用Metal，不过比较困难罢了。</p>
<blockquote>
<p>点评：</p>
<p>Core ML 大大降低了开发者在苹果设备上使用机器学习技术的门槛。苹果制定了自己的模型格式，这样当前主流机器学习模型通过转换工具都能运用到APP当中。Core ML底层是Accelerate BNNS 和MPS，架构如下:</p>
<p><img src="/Users/thinkdeeper/FarBox/thinker.farbox.com/_image/about/21-54-35.jpg" alt="21-54-35"></p>
</blockquote>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/06/30/YOLO：CoreML与MPSNNGraph/" rel="next" title="">
                <i class="fa fa-chevron-left"></i> 
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/07/01/test2/" rel="prev" title="test2">
                test2 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="ghg" />
          <p class="site-author-name" itemprop="name">ghg</p>
           
              <p class="site-description motion-element" itemprop="description">日常所想所思的暂留地</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#YOLO：CoreML与MPSNNGraph"><span class="nav-number">1.</span> <span class="nav-text">YOLO：CoreML与MPSNNGraph</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#YOLO与Core-ML"><span class="nav-number">1.1.</span> <span class="nav-text">YOLO与Core ML</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤1：Darknet-to-Keras-1-2-2"><span class="nav-number">1.1.1.</span> <span class="nav-text">步骤1：Darknet to Keras 1.2.2</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤2：Keras-1-2-2到-Core-ML"><span class="nav-number">1.1.2.</span> <span class="nav-text">步骤2：Keras 1.2.2到 Core ML</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤3：将模型添加到应用程序"><span class="nav-number">1.1.3.</span> <span class="nav-text">步骤3：将模型添加到应用程序</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤4：预测"><span class="nav-number">1.1.4.</span> <span class="nav-text">步骤4：预测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤5：试试吧！"><span class="nav-number">1.1.5.</span> <span class="nav-text">步骤5：试试吧！</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#YOLO与MPSNNGraph"><span class="nav-number">1.2.</span> <span class="nav-text">YOLO与MPSNNGraph</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤1：转换模型"><span class="nav-number">1.2.1.</span> <span class="nav-text">步骤1：转换模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤2：将模型添加到应用程序"><span class="nav-number">1.2.2.</span> <span class="nav-text">步骤2：将模型添加到应用程序</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤3：预测"><span class="nav-number">1.2.3.</span> <span class="nav-text">步骤3：预测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤4：试试吧！"><span class="nav-number">1.2.4.</span> <span class="nav-text">步骤4：试试吧！</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#结论"><span class="nav-number">1.3.</span> <span class="nav-text">结论</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ghg</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  





  

  

  

  

  

  

</body>
</html>
